# Построение выпуклой оболочки (алгоритм Джарвиса)

- **Студент:** Парамонов Леонид Игоревич, группа 3823Б1ПР5  
- **Технология:** SEQ, MPI  
- **Вариант:** 25  

## 1. Введение

В задачах вычислительной геометрии часто требуется найти выпуклую оболочку конечного множества точек на плоскости. Выпуклая оболочка — это минимальный выпуклый многоугольник, содержащий все точки. Алгоритм Джарвиса (или "заворачивания подарка") является одним из классических алгоритмов для решения этой задачи. В данном отчёте представлены последовательная (SEQ) и параллельная на процессах (MPI) реализации алгоритма Джарвиса.

## 2. Постановка задачи

**Формальная постановка:**  
Для множества точек \( P = \{p_1, p_2, ..., p_m\} \) на плоскости требуется найти выпуклую оболочку \( H \), такую что:
1. \( H \) — выпуклый многоугольник
2. Все точки \( P \) лежат внутри или на границе \( H \)
3. \( H \) имеет минимальную площадь среди всех выпуклых многоугольников, удовлетворяющих условию 2

**Входные данные:**
- `points` — вектор точек `Point` (каждая точка содержит координаты `x` и `y` типа `double`)

**Выходные данные:**
- Вектор точек выпуклой оболочки в порядке обхода (против или по часовой стрелке)

**Ограничения:**
- Количество точек должно быть не менее 3
- Точки могут иметь произвольные координаты (включая одинаковые)
- Для корректной работы требуется минимум 3 неколлинеарные точки

## 3. Базовый алгоритм (последовательный)

Алгоритм Джарвиса основан на идее "заворачивания" множества точек:

1. Найти самую левую точку (с минимальной x-координатой)
2. Для текущей точки найти следующую точку оболочки, такую что все остальные точки лежат справа от вектора (current → candidate)
3. Добавить найденную точку в оболочку и сделать её текущей
4. Повторять шаги 2-3 до возвращения в начальную точку

**Сложность:** \(O(m \cdot h)\), где \(m\) — количество точек, \(h\) — количество точек в оболочке.  
В худшем случае \(O(m^2)\), в лучшем \(O(m)\).

## 4. Схема параллелизации (MPI)

**Распределение данных:**  
Все точки рассылаются всем процессам для простоты реализации. Более продвинутые схемы могли бы распределять точки, но в данной реализации используется упрощённый подход:

**Шаги алгоритма:**
1. **Валидация** — проверка, что точек достаточно (на всех процессах)
2. **Вычисление оболочки** — только корневой процесс (rank 0) строит выпуклую оболочку
3. **Рассылка результата** — корневой процесс рассылает результат всем остальным процессам через `MPI_Bcast`

**Диаграмма:**
```
Процесс 0: все точки → алгоритм Джарвиса → выпуклая оболочка
                                          ↓ MPI_Bcast
Процессы 1..p-1: все точки → ожидание → получение результата
```

## 5. Детали реализации

**Структура проекта:**
- `common.hpp` — общие типы данных (`Point`, `InType`, `OutType`, `TestType`)
- `ops_seq.hpp/cpp` — последовательная реализация
- `ops_mpi.hpp/cpp` — MPI-реализация
- `main.cpp` — юнит-тесты и тесты производительности
- `settings.json` — настройки задач

**Ключевые классы:**
- `ParamonovJarvisSEQ` — последовательная версия
- `ParamonovJarvisMPI` — MPI-версия
- `JarvisFuncTests` — класс для функциональных тестов
- `JarvisPerfTests` — класс для тестов производительности

**Особенности реализации:**
- Проверка цикличного сдвига и ориентации при сравнении оболочек
- Нормализация оболочки (поворот к левой нижней точке)
- Обработка коллинеарных точек
- Удаление дубликатов и точек на одной прямой

## 6. Экспериментальная установка

**Процессор:** Intel(R) Core(TM) i5-9600K CPU @ 3.30GHz  
**Оперативная память:** 16 GB, 2133 MHz  
**ОС:** Windows 10  

### Инструменты
**Компилятор:** MSVC v143 (v.14.44—17.14)  
**MPI:** Microsoft MPI v10.1.3 (64-bit)  
**Тип сборки:** Release  

**Тестовые данные:**
1. Функциональные тесты:
   - Квадрат с внутренней точкой
   - Треугольник с точкой внутри
   - Вогнутая L-образная фигура
   - Коллинеарные точки
2. Тесты производительности:
   - 20000 случайных точек в диапазоне [-10000, 10000]

## 7. Результаты и обсуждение

### 7.1 Корректность

Корректность проверяется:
1. Юнит-тестами на различные конфигурации точек
2. Сравнением результатов SEQ и MPI версий
3. Проверкой краевых случаев (менее 3 точек)

Все тесты проходят успешно, включая проверку с учётом циклического сдвига и обратной ориентации.

### 7.2 Производительность

Тестирование на 20000 случайных точках:

| Режим | Количество процессов | Время, с | Ускорение | Эффективность |
|-------|---------------------|----------|-----------|---------------|
| SEQ   | 1                   | 0.215    | 1.00      | N/A           |
| MPI   | 2                   | 0.198    | 1.09      | 54.5%         |
| MPI   | 4                   | 0.195    | 1.10      | 27.5%         |
| MPI   | 6                   | 0.194    | 1.11      | 18.5%         |
| MPI   | 8                   | 0.193    | 1.11      | 13.9%         |

**Анализ:**
- MPI-версия показывает незначительное ускорение
- Низкая эффективность связана с упрощённой схемой параллелизации (все вычисления на процессе 0)
- Основное время тратится на построение оболочки, которое выполняется только одним процессом
- Накладные расходы на рассылку данных незначительны по сравнению с вычислениями

## 8. Выводы

1. Реализованы корректно работающие SEQ и MPI версии алгоритма Джарвиса
2. Алгоритм корректно обрабатывает различные конфигурации точек, включая коллинеарные
3. Текущая MPI-реализация использует упрощённую схему (вычисления только на корневом процессе)
4. Для достижения реального ускорения необходима более сложная схема параллелизации

**Ограничения и возможности улучшения:**
1. **Текущая реализация MPI** не использует преимущества многопроцессорности для вычислений
2. **Возможные улучшения:**
   - Распределение точек между процессами
   - Построение локальных оболочек на каждом процессе
   - Слияние локальных оболочек в глобальную
   - Использование более эффективных алгоритмов (Чана, QuickHull)

## 9. Ссылки

1. Preparata F.P., Shamos M.I. Computational Geometry: An Introduction. — Springer, 1985.
2. Cormen T.H., Leiserson C.E., Rivest R.L., Stein C. Introduction to Algorithms. — MIT Press, 2009.
3. Using MPI: Portable Parallel Programming with the Message-Passing Interface. // Gropp W., Lusk E., Skjellum A. — Cambridge: MIT Press, 2014.
4. Теория и практика параллельных вычислений. // Гергель В.П., Стронгин Р.Г. — М.: Интернет-Университет Информационных Технологий, 2007.

## Приложение

**Ключевой фрагмент алгоритма Джарвиса:**
```cpp
inline OutType BuildHull(const InType &points) {
  if (points.size() < 3) {
    return {};
  }

  OutType hull;
  const std::size_t n = points.size();
  const std::size_t start = FindLeftmost(points);
  std::size_t p = start;
  
  while (true) {
    hull.push_back(points[p]);
    const std::size_t initial_candidate = (p + 1) % n;
    const std::size_t next = SelectNextPoint(points, p, initial_candidate);
    
    if (next == start) {
      break;
    }
    if (next == p) {
      break;
    }
    p = next;
  }

  NormalizeHull(hull);
  return hull;
}
```

**Функция выбора следующей точки:**
```cpp
inline std::size_t SelectNextPoint(const InType &points, 
                                   std::size_t current, 
                                   std::size_t candidate) {
  for (std::size_t i = 0; i < points.size(); i++) {
    if (i == current) continue;
    
    const double cross = Cross(points[current], points[candidate], points[i]);
    const bool better_turn = cross > 0;
    const bool farther_on_line = (cross == 0) && 
         (Dist2(points[current], points[i]) > Dist2(points[current], points[candidate]));
    
    if (better_turn || farther_on_line) {
      candidate = i;
    }
  }
  return candidate;
}
```