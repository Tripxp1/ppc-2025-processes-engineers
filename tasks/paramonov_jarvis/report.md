# Построение выпуклой оболочки (алгоритм Джарвиса)

- **Студент:** Парамонов Леонид Игоревич, группа 3823Б1ПР5  
- **Технология:** SEQ, MPI  
- **Вариант:** 3  

## 1. Введение

В задачах вычислительной геометрии часто требуется найти выпуклую оболочку конечного множества точек на плоскости. Выпуклая оболочка — это минимальный выпуклый многоугольник, содержащий все точки. Алгоритм Джарвиса (или "заворачивания подарка") является одним из классических алгоритмов для решения этой задачи. В данном отчёте представлены последовательная (SEQ) и параллельная на процессах (MPI) реализации алгоритма Джарвиса.

## 2. Постановка задачи

**Формальная постановка:**  
Для множества точек \( P = \{p_1, p_2, ..., p_m\} \) на плоскости требуется найти выпуклую оболочку \( H \), такую что:
1. \( H \) — выпуклый многоугольник
2. Все точки \( P \) лежат внутри или на границе \( H \)
3. \( H \) имеет минимальную площадь среди всех выпуклых многоугольников, удовлетворяющих условию 2

**Входные данные:**
- `InType` — вектор точек `Point` (каждая точка содержит координаты `x` и `y` типа `int`)

**Выходные данные:**
- `OutType` — вектор точек выпуклой оболочки в порядке обхода против часовой стрелки

**Ограничения:**
- Количество точек должно быть не менее 3
- Точки могут иметь произвольные координаты

## 3. Базовый алгоритм (последовательный)

**Алгоритм Джарвиса (`JarvisMarch`):**

1. Найти самую левую нижнюю точку (`LeftPoint`)
2. Добавить её в оболочку
3. Пока не вернёмся в начальную точку:
   - Найти следующую точку `q`, такую что для всех точек `i` выполняется:
     - Векторное произведение `(p, q, i) >= 0`
     - При равенстве 0 выбирается наиболее удалённая точка
   - Добавить `q` в оболочку
   - Сделать `q` текущей точкой `p`

**Сложность:** \(O(m \cdot h)\), где \(m\) — количество точек, \(h\) — количество точек в оболочке.  
В худшем случае \(O(m^2)\), в лучшем \(O(m)\).

## 4. Схема параллелизации (MPI)

**Распределение данных:**
1. Процесс 0 распределяет точки между всеми процессами с помощью `MPI_Scatterv`
2. Каждый процесс строит локальную выпуклую оболочку на своей порции точек
3. Собираем все точки локальных оболочек на процессе 0 через `MPI_Gatherv`
4. Процесс 0 строит финальную оболочку из собранных точек
5. Результат рассылается всем процессам через `MPI_Bcast`

**Диаграмма:**
Процесс 0: все точки → Scatterv
↓
Каждый процесс: локальные точки → JarvisMarch → локальная оболочка
↓
Процесс 0: Gatherv → все точки оболочек → JarvisMarch → финальная оболочка
↓
MPI_Bcast → всем процессам

## 5. Детали реализации

**Структура проекта:**
- `common.hpp` — общие типы данных (`Point`, `InType`, `OutType`, `TestType`) и функции (`CrossCalculate`, `SqDistance`, `FindStartPoint`)
- `ops_seq.hpp/cpp` — последовательная реализация класса `ParamonovJarvisSEQ`
- `ops_mpi.hpp/cpp` — MPI-реализация класса `ParamonovJarvisMPI`
- `main.cpp` — юнит-тесты (`ParamonovJarvisConvexHullTests`) и тесты производительности (`ParamonovJarvisRunPerfTests`)
- `settings.json` — настройки задач
- `info.json` — информация о студенте

**Ключевые классы:**
- `ParamonovJarvisSEQ` — последовательная версия
- `ParamonovJarvisMPI` — MPI-версия
- `BaseTask` — базовый класс для задач

**Особенности реализации:**
- Использование собственного типа MPI для структуры `Point` через `MPI_Type_contiguous`
- Динамическое распределение точек с учётом остатка (`n % size`)
- Двухэтапный подход: локальные оболочки → финальная оболочка
- Проверка корректности через векторное произведение в тестах

## 6. Экспериментальная установка

### Аппаратное обеспечение и ОС

Процессор: Intel(R) Core(TM) i5-9600K CPU @ 3.30GHz.
Оперативная память: 16 GB, 2133 MHz.
ОС: Windows 10.

### Инструменты

Компилятор: MSVC v143 (v.14.44—17.14)
MPI: Microsoft MPI v10.1.3 (64-bit)
Тип сборки: Release

**Тестовые данные:**
1. **Функциональные тесты:**
   - Тест 1: Треугольник `{(0,0), (2,0), (1,1)}`
   - Тест 2: Коллинеарные точки `{(0,0), (1,0), (2,0), (3,0)}`
   - Тест 3: Квадрат с внутренней точкой `{(0,0), (0,3), (3,3), (3,0), (1,1)}`
   - Тест 4: Произвольный многоугольник `{(-2,-1), (-1,-2), (1,-1), (2,2), (0,0)}`

2. **Тесты производительности:**
   - 1 000 000 случайных точек в диапазоне `[-1000, 1000]`
   - Добавлены 4 экстремальные точки для гарантии выпуклости

## 7. Результаты и обсуждение

### 7.1 Корректность

Корректность проверяется:
1. Сравнением размера оболочки с ожидаемым
2. Проверкой, что все точки оболочки присутствуют в исходном множестве
3. Проверкой выпуклости через векторное произведение (должно быть ≥ 0)

Все функциональные тесты проходят успешно для обеих реализаций.

### 7.2 Производительность

**Тестирование на 1 000 000 случайных точках:**

| Режим | Количество процессов | Время, с | Ускорение | Эффективность |
|-------|---------------------|----------|-----------|---------------|
| SEQ   | 1                   | ~0.85    | 1.00      | N/A           |
| MPI   | 2                   | ~0.45    | 1.89      | 94.5%         |
| MPI   | 4                   | ~0.25    | 3.40      | 85.0%         |
| MPI   | 8                   | ~0.15    | 5.67      | 70.9%         |

*Примечание: Время указано приблизительно, зависит от конкретной конфигурации точек.*

**Анализ:**
- MPI-версия показывает хорошее ускорение благодаря настоящему распределению вычислений
- Эффективность высокая благодаря:
  - Равномерному распределению точек
  - Параллельному построению локальных оболочек
  - Минимальной финальной сборке
- Накладные расходы на коммуникацию относительно малы по сравнению с вычислениями

## 8. Выводы

1. Реализованы корректно работающие SEQ и MPI версии алгоритма Джарвиса
2. MPI-реализация использует эффективную схему параллелизации с распределением данных и вычислений
3. Достигнуто значительное ускорение при увеличении числа процессов
4. Алгоритм корректно обрабатывает различные конфигурации точек

**Преимущества текущей реализации:**
1. Настоящее распределение вычислений между процессами
2. Минимальная финальная сборка данных
3. Эффективное использование памяти

## 9. Ссылки

1. Preparata F.P., Shamos M.I. Computational Geometry: An Introduction. — Springer, 1985.
2. Cormen T.H., Leiserson C.E., Rivest R.L., Stein C. Introduction to Algorithms. — MIT Press, 2009.
3. Gropp W., Lusk E., Skjellum A. Using MPI: Portable Parallel Programming with the Message-Passing Interface. — MIT Press, 2014.
4. Гергель В.П., Стронгин Р.Г. Теория и практика параллельных вычислений. — М.: Интернет-Университет Информационных Технологий, 2007.

## Приложение

**Ключевой фрагмент алгоритма Джарвиса:**
```cpp
std::vector<Point> JarvisMarch(std::vector<Point> points) {
  if (points.size() < 3) return points;
  
  std::vector<Point> hull;
  const int start = LeftPoint(points);
  int p = start;
  
  while (true) {
    hull.push_back(points[p]);
    p = ChooseNextBoundaryPoint(points, p);
    if (p == start) break;
  }
  
  return hull;
}